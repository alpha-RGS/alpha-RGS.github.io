<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Score-based Source Separation with Applications to Digital Communication Signals</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Scored-based Source Separation with Applications to Digital Communication Signals</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/tkj97/">Tejas K. Jayashankar</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/garyleecf/">&nbspGary C.F. Lee</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://a-lancho.github.io/">&nbspAlejandro Lancho</a><sup>1, 2</sup>, 
            </span>
            <span class="author-block">
              <a href="https://www.weissamir.com">&nbspAmir Weiss</a><sup>1</sup> 
            </span>
            <br />
            <span class="author-block">
              <a href="https://people.lids.mit.edu/yp/homepage/">Yury Polyanskiy</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="http://allegro.mit.edu/~gww/">&nbspGregory W. Wornell</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Massachusetts Institute of Technology</span>
            <span class=""author-block>&nbsp&nbsp&nbsp&nbsp</span>
            <span class="author-block"><sup>2</sup>Universidad Carlos III de Madrid</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2306.14411.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2306.14411"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tkj516/score_based_source_separation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose a new method for separating superimposed sources using diffusion-based generative models.  
            Our method relies only on separately trained statistical priors of independent sources to establish 
            a new objective function guided by <em>maximum a posteriori</em> estimation with an <em>&alpha;-posterior</em>, 
            across multiple levels of Gaussian smoothing.  Motivated by applications in radio-frequency (RF) systems, 
            we are interested in sources with underlying discrete nature and the recovery of encoded bits from a signal 
            of interest, as measured by the bit error rate (BER). Experimental results with RF mixtures demonstrate 
            that our method results in a BER reduction of 95%  over classical and existing learning-based methods.  
            Our analysis demonstrates that our proposed method yields solutions that asymptotically approach the 
            modes of an underlying discrete distribution. Furthermore, our method can be viewed as a multi-source 
            extension to the recently proposed score distillation sampling scheme, shedding additional light on its 
            use beyond conditional sampling.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <br />
    <br />
    <br />

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overall Pipeline</h2>
        <div class="results-image">
          <img src="./static/images/digital_comm_github.png"
          class="results-image"
          alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <br />
          <p>
            At a high level, digital communications deals with the transmission 
            of bits by modulating a so-called "carrier signal".  Groups of bits, 
            from which the underlying discreteness of these sources originates, 
            are first mapped to complex-valued symbols via the <em>digital 
            constellation</em> &mdash; a mapping between groups of bits and a finite 
            set of complex-valued symbols.  These symbols are subsequently
            aggregated to form a <em>complex-valued continuous waveform</em> after 
            filtering by a pulse-shaping function. The constellation is chosen 
            (among other considerations) by the number of bits modulated simultaneously.  
            Common schemes include modulating two bits at a time (Quadrature Phase Shift Keying, or QPSK),  
            or one bit at a time (Binary Phase Shift Keying, or BPSK).  To recover 
            the bits at the receiver, one may adopt <em>matched filtering</em> (MF) 
            before the estimation of the underlying symbols, and thereafter decode 
            them back to bits. 
          </p>
          <p>
            Mitigating co-channel intereference is a challenging problem, especially
            in heterogeneous wireless systems, i.e., a wireless system with many
            different communication devices.  In the figure, this is represented
            as an additive signal b(t) with a scaling factor &kappa; after modulation
            of the bits onto a carrier wave, which is known as the signal of interest
            (SOI).  We envision an intelligent decoder that uses our proposed solution
            to reverse the effects of the interference by leveraging independently
            trained statistical priors over the SOI and interference signals.
          </p>
        </div>
      </div>
    </div>

    <br />
    <br />
    <br />

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">&alpha;-Posterior with Randomized Gaussian Smoothing (&alpha;-RGS)</h2>
        <div class="results-image">
          <img src="./static/images/algorithm.png"
          class="results-image"
          alt="Interpolate start reference image."/>
        </div>
        <!-- <div class="content has-text-justified">
          <br />
          <p>
            At a high level, digital communications deals with the transmission 
            of bits by modulating a so-called "carrier signal".  Groups of bits, 
            from which the underlying discreteness of these sources originates, 
            are first mapped to complex-valued symbols via the <em>digital 
            constellation</em> &mdash; a mapping between groups of bits and a finite 
            set of complex-valued symbols.  These symbols are subsequently
            aggregated to form a <em>complex-valued continuous waveform</em> after 
            filtering by a pulse-shaping function. The constellation is chosen 
            (among other considerations) by the number of bits modulated simultaneously.  
            Common schemes include modulating two bits at a time (Quadrature Phase Shift Keying, or QPSK),  
            or one bit at a time (Binary Phase Shift Keying, or BPSK).  To recover 
            the bits at the receiver, one may adopt <em>matched filtering</em> (MF) 
            before the estimation of the underlying symbols, and thereafter decode 
            them back to bits. 
          </p>
          <p>
            Mitigating co-channel intereference is a challenging problem, especially
            in heterogeneous wireless systems, i.e., a wireless system with many
            different communication devices.  In the figure, this is represented
            as an additive signal b(t) with a scaling factor &kappa; after modulation
            of the bits onto a carrier wave, which is known as the signal of interest
            (SOI).  We envision an intelligent decoder that uses our proposed solution
            to reverse the effects of the interference by leveraging independently
            trained statistical priors over the SOI and interference signals.
          </p>
        </div> -->
      </div>
    </div>

    <br />
    <br />
    <br />

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="results-image">
          <img src="./static/images/results.png"
          class="results-image"
          alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <br />
          <p>
            Each row in the figure above shows source separation results for a
            different mixture.  Across the board, our proposed method with an 
            analytical or learned score function for the SOI outperforms all other 
            baselines (matched filtering (MF), linear minimum mean squared error (LMMSE),
            reverse diffusion and BASIS separation) in terms of bit error rate 
            (BER) and mean squared error (MSE).
          </p>
          <p>
            We train diffusion models on different RF datasets &mdash; i) synthetic 
            QPSK signals with RRC pulse shaping, ii) synthetic OFDM signals 
            (BPSK and QPSK) with structure similar to IEEE 802.11 WiFi signals; 
            and iii)  signals corresponding to "CommSignal2" from the 
            <a href="https://rfchallenge.mit.edu/">RF Challenge</a>, which contains 
            datasets of over-the-air recorded signals.  All synthetic datasets 
            were created using the <a href="https://developer.nvidia.com/sionna">
            NVIDIA Sionna toolkit</a>.
          </p>
          <p>
            As expected, our best results are obtained by leveraging the prior 
            knowledge, in the form of the analytical score for the SOI.  
            Nevertheless, our learned SOI score can nearly mimic this performance, 
            and despite the slight degradation still outperforms all baselines 
            in terms of BER as well. It should be noted that CommSignal2 contains 
            small amount of background noise, which is amplified at low SIR 
            (high &kappa;). This noise constrains the minimal achievable BER 
            even under the assumption of only having the residual AWGN present, 
            illustrated by the black dotted line in the bottom left plot. Nevertheless,
            out proposed method outperforms all baselines.
          </p>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  <!-- </div>
</section> -->


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{jayashankar2023score,
      title={Score-based Source Separation with Applications to Digital Communication Signals},
      author={Jayashankar, Tejas and Lee, Gary C.F. and Lancho, Alejandro and Weiss, Amir and Polyanskiy, Yury and Wornell, Gregory W.},
      journal={arXiv preprint arXiv:2306.14411},
      year={2023}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align:center">
              This work is part of a larger body of projects that fall under the
              umbrella of the RF Challenge, a challenge dedicated to developing 
              intelligent digital communication technology for the next generation 
              of AI-enhanced wireless communication standards.
            </p>
          </div>
        </div>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
          <div class="navbar-item has-dropdown is-hoverable"; style="justify-content: center;">
            <a class="navbar-link">
              Explore the RF Challenge
            </a>
            <div class="navbar-dropdown">
              <a class="navbar-item" href="https://rfchallenge.mit.edu/icassp24-single-channel">
                ICASSP 2024 SP Grand Challenge
              </a>
              <a class="navbar-item" href="https://rfchallenge.mit.edu/challenge-1/">
                Single Channel RF-Challenge
              </a>
              <a class="navbar-item" href="https://rfchallenge.mit.edu/challenge-2/">
                Multi-Channel Signal Separation Challenge
              </a>
              <a class="navbar-item" href="https://rfchallenge.mit.edu/challenge-3/">
                Cyber-RF Anamoly Detector Challenge
              </a>
            </div>
          </div>
        </div>
      </div>
      <a class="icon-link" href="https://github.com/RFChallenge" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://rfchallenge.mit.edu/">
        <i class="fas fa-home"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align:center">
            The source code for this website is borrowed from <a
              href="https://nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
